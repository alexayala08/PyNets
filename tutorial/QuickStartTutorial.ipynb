{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A PyNets Primer in Python and Bash\n",
    "\n",
    "Docker/Singularity containers are the preferable way to run PyNets because the compute environment will include all optional dependencies, fully unlocked plotting capabilities, and will perform predictably and with fully reproducible numerical precision. To keep things simple for this demonstration, however, let's begin by just installing PyNets in a virtual environment and then run the workflow manually on some example data. The scope of this tutorial will cover single-subject workflows. For more examples (i.e. including usage with docker/singularity), see: https://pynets.readthedocs.io/en/latest/usage.html\n",
    "\n",
    "Although we will explore the package interactively in the code that follows, bear in mind that PyNets is a *workflow*, not a library like its core dependencies (Dipy, Nilearn, Nipype, Networkx). Thus, demonstrating its usage is fundamentally a command-line endeavor, rather than a purely pythonic one to which you may be typically accustomed. \n",
    "\n",
    "PyNets was intentionally designed to scale with supercomputers, but also run using just a couple cores on your local laptop. Although this tutorial is designed to explore the latter use-case, ideally the user will also have (or acquire) **systems-level** thinking (an awareness of issues relevant to distributed/parallel computing) in order to make the most of what PyNets has to offer for ensemble connectome learning on your institution's HPC or using AWS batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Assuming that python3, pip, and FSL are already installed...\n",
    "# Start a virtual environment and install some dependencies for our lesson.\n",
    "pip install virtualenv --user\n",
    "mkdir ~/virtualenvironment 2>/dev/null\n",
    "virtualenv ~/virtualenvironment/pynets\n",
    "cd ~/virtualenvironment/pynets/bin\n",
    "source activate\n",
    "./pip3 install -U gdown fury # for downloading data, running pynets, and some 3d viz\n",
    "./pip3 install pynets=='0.9.998c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# The only GUI-based visualizer that I continue to use (personally) is fsleyes,\n",
    "# which I find to be immensely intuitive, especially for fine-grained QC of overlays.\n",
    "# But feel free to use an image viewer of your choice. Future PyNets versions will likely \n",
    "# include html-style reports.\n",
    "# For macs, download this link for fsleyes:\n",
    "wget https://fsl.fmrib.ox.ac.uk/fsldownloads/fsleyes/FSLeyes-latest-macos.tar.gz #for 2d viz\n",
    "#rm -rf ~/virtualenvironment/FSLeyes.app\n",
    "tar -xzvf FSLeyes-latest-macos.tar.gz -C ~/virtualenvironment\n",
    "# For Linux, downnload the appropriate precompiled build from https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLeyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch sample preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download a minimal dataset from OASIS that includes preprocessed, multimodal fMRI and dMRI data.\n",
    "\n",
    "*Note*: Normally, we could just use a dataset from datalad or from s3 (which will download automatically using an s3:// file path prefix if your AWS credentials are properly configured!). See `pynets_cloud` CLI , with examples here: https://pynets.readthedocs.io/en/latest/usage.html#quickstart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Now we create an output directory for the derivatives of the pipeline (if one doesn't exist already).\n",
    "if  [ -d ~/Downloads/.pynets ]; then\n",
    "    rm -rf ~/Downloads/.pynets/test_oasis*\n",
    "else\n",
    "    mkdir ~/Downloads/.pynets\n",
    "fi\n",
    "\n",
    "# And download the data to a generic \"derivatives\" directory.\n",
    "if  [ ! -f ~/Downloads/.pynets/test_oasis.tar.gz ]; then\n",
    "    cd ~/Downloads/.pynets\n",
    "    gdown https://drive.google.com/uc?id=1beEoc_Pdk6OBDYc80mBDTvUhcUny9Gu3 -O ~/Downloads/.pynets/test_oasis.tar.gz\n",
    "else\n",
    "    cd ~/Downloads/.pynets\n",
    "fi\n",
    "\n",
    "mkdir ~/Downloads/.pynets/derivatives/sub-OAS31172 2>/dev/null\n",
    "tar -xzvf test_oasis.tar.gz -C derivatives/sub-OAS31172"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Functional Connectometry\n",
    "\n",
    "*Note: Depending on the CPU/memory resources available to this jupyter notebook, and whether segmentation and registration data already exist from prior runs, the following commands may take anywhere between 5-240 minutes to run (it takes ~58 minutes on my laptop with 8 vCPUs and 16 GB RAM). This wide range of execution times stems from the fact that ensemble sampling in PyNets is 'embaressingly parallelizable' across estimations, with no ceiliing on scalability other than available compute resources. For the example below, for instance, if you had access to 68 vCPUs (as is found on TACC's Stampede2, for instance), with plenty of free RAM on a large-memory node, you could arrive at the 144 connectome sample in the time it takes to sample just one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a command-line call for a single subject from the data we just downloaded. We can do this in two ways -- (1) using the `pynets_bids` API since our sample data is in BIDS format and can be queried using pybids; (2) with the `pynets` API for comparison.\n",
    "So, for run 1 of session d0407 from subject OAS31172, lets sample an ensemble of 144 functional connectome estimates (1 models x 6 thresholds x 2 smoothing values x 2 high-pass filter thresholds x 3 atlases x 2 time-series extraction methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dir=~/Downloads/.pynets\n",
    "abs_dir=`echo \"$(dirname $dir)\"`\n",
    "\n",
    "# BIDS way using a pre-configured .json file that specifies how we want the pipeline to run.\n",
    "# We can view this file to get an idea of what it contains:\n",
    "cat ~/virtualenvironment/pynets/lib/python3.7/site-packages/pynets/config/bids_config_bold.json\n",
    "\n",
    "# Next we initiate the `pynets_bids` CLI (note the inclusion of a run_label since the BOLD acquisitions for this dataset contain two runs):%%bash\n",
    "~/virtualenvironment/pynets/bin/pynets_bids \"$abs_dir\"/.pynets/derivatives \"$abs_dir\"/.pynets/outputs participant func --participant_label OAS31172 --session_label d0407 --run_label 1 -config ~/virtualenvironment/pynets/lib/python3.7/site-packages/pynets/config/bids_config_bold.json\n",
    "\n",
    "# *Note that the configuration in `bids_config_bold.json` is equivalent to running the following (non-BIDS) CLI call that does not require a config file:\n",
    "# ~/virtualenvironment/pynets/bin/pynets \"$abs_dir\"/.pynets/outputs -id OAS31172_d0407_1 -mod 'partcorr' -min_thr 0.20 -max_thr 0.80 -step_thr 0.10 -sm 0 4 -hp 0 0.028 -a 'BrainnetomeAtlasFan2016' 'atlas_harvard_oxford' 'destrieux2009_rois' -es 'mean' 'variance' -anat \"$abs_dir\"/.pynets/derivatives/sub-OAS31172/ses-d0407/anat/sub-OAS31172_ses-d0407_run-01_T1w.nii.gz -func \"$abs_dir\"/.pynets/derivatives/sub-OAS31172/ses-d0407/func/sub-OAS31172_ses-d0407_task-rest_run-01_bold.nii.gz -plug 'MultiProc' -work '/tmp/pynets_work' -mst -plt -embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/func\n",
    "ls\n",
    "\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a bit of quality-control to ensure, for example, that the inverse warping of the destrieux2009_rois atlas from template-space to native T1w anatomical space is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "t1w_image=`ls /tmp/pynets_work/*/*/meta_wf_*/fmri_connectometry*/register_node/reg/imgs/*t1w_brain.nii.gz | head -1`\n",
    "atlas_in_t1w_image=`ls /tmp/pynets_work/*_wf_single_subject_fmri*/wf_single_*/meta_wf_*/fmri_connectometry_*/_atlas_destrieux2009_rois/register_atlas_node/atlas_destrieux2009_rois/*_gm.nii.gz | head -1`\n",
    "\n",
    "~/virtualenvironment/FSLeyes.app/Contents/*/fsleyes \"$t1w_image\" \"$atlas_in_t1w_image\" -cm 'random' &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below multiplot depicts distributions of average graph topological metrics, calculated using Area-Under-the-Curve (AUC) across our window of multiple thresholds, for the ensemble of 144 connectomes sampled. As you can visually discern, topology varies considerably across estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image\n",
    "Image(filename=glob.glob('/Users/*/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/func/mean_global_topology_distribution_multiplot.png')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=glob.glob('/Users/*/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/func/BrainnetomeAtlasFan2016/figures/OAS31172_d0407_1_modality-func_est-partcorr_nodetype-parc_smooth-4fwhm_hpass-0.028Hz_extract-mean_thr-0.2_glass_viz.png')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a glass brain depiction of left hemisphere regions of the Brainnetome atlas (Fan et al., 2016) using a partial correlation estimator, 4 fwhm smoothing, 0.028Hz high-pass filter, based on variance of the node-extracted time-series, with 20% post-hoc thresholding using the Minimum-Spanning Tree (MST) method. The latter method serves as an anti-fragmentation device that ensures we can prevent isolated (i.e. disconnected) nodes that can violate certain graph theoretical assumptions.\n",
    "\n",
    "In the visualization, node size conveys the level of node importance (smaller is lower eigenvector centrality) and node color corresponds to hierarchical Louvain community affiliation (5 distinct communities found).\n",
    "\n",
    "The below adjacency matrix depicts a single connectome estimate, with community affiliation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=glob.glob('/Users/*/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/func/BrainnetomeAtlasFan2016/figures/OAS31172_d0407_1_modality-func_est-partcorr_nodetype-parc_smooth-4fwhm_extract-variance_thr-0.8_adj_mat_comm.png')[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also look at the mean connectome (i.e. across all 144 estimates) -- what we might from here on out refer to as an **omnetome** as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from nilearn.plotting import plot_matrix\n",
    "from pynets.core.thresholding import standardize\n",
    "\n",
    "mats = [np.load(i) for i in glob.glob('/Users/*/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/func/BrainnetomeAtlasFan2016/graphs/*.npy')]\n",
    "\n",
    "mean_mat = standardize(np.mean([mat for mat in mats if mat.shape==(244,244)], axis=0))\n",
    "\n",
    "plot_matrix(\n",
    "    mean_mat,\n",
    "    figure=(10, 10),\n",
    "    labels=[' ']*len(mean_mat),\n",
    "    vmax=np.percentile(mean_mat[mean_mat > 0], 90),\n",
    "    vmin=np.percentile(mean_mat[mean_mat > 0], 10),\n",
    "    reorder=\"average\",\n",
    "    auto_fit=True,\n",
    "    grid=False,\n",
    "    colorbar=True,\n",
    "    cmap='RdBu_r',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get a much more information-rich graph. This graph, unlike the first, now represents a new *distribution* of connectomes, that, by virtue of its plurality of views, more exhaustively samples from the true *population* of networks in this individual that may exhibit connectivity, across the whole brain as a region of interest, at any point in time during the course of the 5-10 minute resting-state time-series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Outputs\n",
    "So, we explored the outputs of our connectome ensemble visually, but let's take a closer look at our omnetome's topology. To do this, we run another workflow using the `pynets_collect` CLI, which collects the various graph topological metrics extracted from each of the connectome point estimates in our ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dir=~/Downloads/.pynets\n",
    "abs_dir=`echo \"$(dirname $dir)\"`\n",
    "pynets_collect -basedir \"$abs_dir\"/.pynets/outputs -modality 'func'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Now we can load a dataframe of summary topological graph metrics for the run for this particular subject.\n",
    "# Note that if we were to sample connectomes from multiple subjects, the previous pynets_collect CLI would\n",
    "# simply append new rows to the dataframe per subject run.\n",
    "p = str(Path('~').expanduser()) + '/Downloads/.pynets/outputs/all_subs_neat.csv'\n",
    "df = pd.read_csv(p, index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Connectometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we construct a command-line call for the same subject, but using their dMRI data instead. This time, we should ideally use a higher voxel resolution (1mm) since we are working with microstructure data, but this would increase runtime by as much as 50%, which would be better saved for HPC environments. For demonstration purposes, we will therefore downsample our data slightly and work in 2mm voxel resolution.\n",
    "\n",
    "So, for run 1 of session d0407 from subject OAS31172, lets sample an ensemble of 72 structural connectome estimates (1 diffusion model type x 6 thresholds x 2 direction-getting methods x 2 minimum streamline length thresholds x 3 atlases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "%%capture\n",
    "\n",
    "# Again, get the absolute paths to files and directories we will use.\n",
    "# The CLI's in PyNets do NOT accept relative paths.\n",
    "dir=~/Downloads/.pynets\n",
    "abs_dir=`echo \"$(dirname $dir)\"`\n",
    "\n",
    "# BIDS way using a pre-configured .json file that specifies how we want the pipeline to run.\n",
    "# We can view this file to get an idea of what it contains:\n",
    "cat ~/virtualenvironment/pynets/lib/python3.7/site-packages/pynets/config/bids_config_dwi.json\n",
    "\n",
    "# Next we initiate the `pynets_bids` CLI:\n",
    "~/virtualenvironment/pynets/bin/pynets_bids \"$abs_dir\"/.pynets/derivatives \"$abs_dir\"/.pynets/outputs participant dwi --participant_label OAS31172 --session_label d0407 -config ~/virtualenvironment/pynets/lib/python3.7/site-packages/pynets/config/bids_config_dwi.json\n",
    "\n",
    "# *Note that the configuration in `bids_config_dwi.json` is equivalent to running the following (non-BIDS) CLI call that does not require a config file:\n",
    "#~/virtualenvironment/pynets/bin/pynets \"$abs_dir\"/.pynets/outputs -mod 'csa' -min_thr 0.20 -max_thr 0.80 -step_thr 0.10 -dg 'det' 'prob' -ml 20 0 -a 'BrainnetomeAtlasFan2016' 'atlas_harvard_oxford' 'destrieux2009_rois' -anat \"\"$abs_dir\"/.pynets/derivatives/sub-OAS31172/ses-d0407/anat/sub-OAS31172_ses-d0407_run-01_T1w.nii.gz\" -dwi \"\"$abs_dir\"/.pynets/derivatives/sub-OAS31172/ses-d0407/dwi/sub-OAS31172_ses-d0407_dwi.nii.gz\" -bval \"\"$abs_dir\"/.pynets/derivatives/sub-OAS31172/ses-d0407/dwi/sub-OAS31172_ses-d0407_dwi.bval\" -bvec \"\"$abs_dir\"/.pynets/derivatives/sub-OAS31172/ses-d0407/dwi/sub-OAS31172_ses-d0407_dwi.bvec\" -id OAS31172_d0407_1 -plug 'MultiProc' -work '/tmp/pynets_work' -mst -plt -vox '2mm' -embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/dwi\n",
    "ls .\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a bit of quality-control to ensure, for example, that the inverse warping of the harvard_oxford atlas from template-space to native DWI anatomical space is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "t1w_dwi_image=`ls /tmp/pynets_work/*/*/meta_wf_*/dmri_connectometry*/register_node/dmri_reg/reg/imgs/t1w_in_dwi.nii.gz | head -1`\n",
    "atlas_in_t1w_dwi_image=`ls /tmp/pynets_work/*_wf_single_subject_dmri*/wf_single_*/meta_wf_*/dmri_connectometry_*/*/register_atlas_node/atlas_atlas_harvard_oxford/atlas_harvard_oxford_dwi_track.nii.gz | head -1`\n",
    "density_map=`ls ~/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/dwi/atlas_harvard_oxford/tractography/*.nii.gz | head -1`\n",
    "\n",
    "~/virtualenvironment/FSLeyes.app/Contents/*/fsleyes \"$t1w_dwi_image\" \"$atlas_in_t1w_dwi_image\" -cm 'random' \"$density_map\" &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image\n",
    "Image(filename=glob.glob('/Users/*/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/dwi/BrainnetomeAtlasFan2016/figures/OAS31172_d0407_modality-dwi_est-csa_nodetype-parc_samples-50000streams_tt-local_dg-det_ml-20_thr-0.2_glass_viz.png')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is a glass brain depiction of regions of the Desikan Klein 2012 atlas using a tensor model estimator of diffusion, deterministic tractography, a minimum fiber length threshold of 20, with 80% post-hoc thresholding using the Minimum-Spanning Tree (MST) method.\n",
    "Again, un the visualization, node size conveys the level of node importance (smaller is lower eigenvector centrality) and node color corresponds to hierarchical Louvain community affiliation (only two distinct communities found). Unlike in the functional case, however, edges are here depicted with dotted white lines to differentiate them from functional edges, which carry a different meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=glob.glob('/Users/*/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/dwi/atlas_harvard_oxford/figures/OAS31172_d0407_modality-dwi_est-csa_nodetype-parc_samples-50000streams_tt-local_dg-det_ml-20_thr-0.2_adj_mat_comm.png')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above adjacency matrix depicts a single connectome estimate, with community affiliation. But we could also look at a structural omnetome (i.e. based on FA-weighted fiber counts) across all 72 independent connectome estimations. Note that by default pynets only samples 50,000 streamlines whose endpoints intersect with at least two parcellation regions after all tissue/waymask/minimum-length filtering. This keeps runtimes down to <60 minutes for the complete structural connectometry pipeline. Bear in mind, however, that across our ensemble sample, we are **actually** sampling 50,000 x 72 = 3.6 million streamlines! And since we are further employing ensemble tractography, which samples across 5 step sizes (0.1, 0.2, 0.3, 0.4, 0.5) and 2 curvature thresholds (30, 40) by default, we are actually indirectly sampling across a much wider grid of parameters still.\n",
    "\n",
    "Whereas in the functional connectometry case, we examined the mean connectome across estimates, here we might choose to examine the max connectome specifically, since structural connectomes are inherently sparser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from nilearn.plotting import plot_matrix\n",
    "from pynets.core.thresholding import standardize\n",
    "\n",
    "mats = [np.load(i) for i in glob.glob('/Users/*/Downloads/.pynets/outputs/sub-OAS31172/ses-d0407/dwi/BrainnetomeAtlasFan2016/graphs/*.npy')]\n",
    "\n",
    "max_mat = standardize(np.max([mat for mat in mats if mat.shape==(246,246)], axis=0))\n",
    "\n",
    "\n",
    "plot_matrix(\n",
    "    max_mat,\n",
    "    figure=(10, 10),\n",
    "    labels=[' ']*len(max_mat),\n",
    "    vmax=np.percentile(max_mat[max_mat > 0], 95),\n",
    "    vmin=np.percentile(max_mat[max_mat > 0], 10),\n",
    "    reorder=\"average\",\n",
    "    auto_fit=True,\n",
    "    grid=False,\n",
    "    colorbar=False,\n",
    "    cmap='RdBu_r',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get a much more information-rich graph. This graph, unlike the first, now represents a new *distribution* of connectomes, that, by virtue of its plurality of views, more exhaustively samples from the true *population* of networks in this individual that may exhibit connectivity, across the whole brain as a region of interest.\n",
    "\n",
    "# Collecting Outputs\n",
    "Now, we explored the outputs of our connectome ensemble visually, but let's take a closer look at the actual topological data. To do this, we run another workflow using the `pynets_collect` CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dir=~/Downloads/.pynets\n",
    "abs_dir=`echo \"$(dirname $dir)\"`\n",
    "pynets_collect -basedir \"$abs_dir\"/.pynets/outputs -modality 'dwi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Now we can load a dataframe of summary topological graph metrics for the run for this particular subject.\n",
    "# Note that if we were to sample connectomes from multiple subjects, the previous pynets_collect CLI would\n",
    "# simply append new rows to the dataframe per subject run.\n",
    "p = str(Path('~').expanduser()) + '/Downloads/.pynets/outputs/all_subs_neat.csv'\n",
    "df = pd.read_csv(p, index_col=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later tutorials will cover a variety of additional topics, including how you can deploy PyNets across entire BIDS datasets in a single command-line interface (CLI) call, benchmark and optimize connectome ensembles across diverse analytic scenarios with GridSearchCV integration, along with more advanced topics such as performing and visualizing multiplex graph analysis and embeddings of multimodal connectomes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
